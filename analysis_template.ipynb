{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f354adf8",
   "metadata": {},
   "source": [
    "# Give your Notebook a title\n",
    "Say what it is about in general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79876c48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T20:21:08.333684300Z",
     "start_time": "2023-05-21T20:21:05.780892500Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# you can use this for averaging etc if you want\n",
    "import numpy\n",
    "\n",
    "# import whatever you want from your own code, for instance:\n",
    "from corpusreader import CorpusReader\n",
    "from generate import *\n",
    "from model import BigramModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fa6b96",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "We begin by building our model from the training set. We use this throughout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7efa7687",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T20:21:09.479287600Z",
     "start_time": "2023-05-21T20:21:09.441880100Z"
    }
   },
   "outputs": [],
   "source": [
    "# set path to training set\n",
    "path = \"./train\"\n",
    "reader = CorpusReader(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7093cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T20:21:18.734135800Z",
     "start_time": "2023-05-21T20:21:12.345707Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding boundaries: 100%|█████████████████████████████████| 11909/11909 [00:00<00:00, 1294879.23it/s]\n",
      "Making and counting Unigrams: 100%|███████████████████████| 11909/11909 [00:00<00:00, 445413.15it/s]\n",
      "Making and counting Bigrams: 100%|█████████████████████████| 11909/11909 [00:00<00:00, 69566.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "my_model = BigramModel(reader.sents())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13b41d4",
   "metadata": {},
   "source": [
    "## Experimenting with smoothing constants\n",
    "\n",
    "Smoothing constants are used both for generating samples and for computing the perplexity of text. To investigate the effect of smoothing constants on generating samples and computing perplexity of samples, we (provide functions? write code?) that allow us to try a range of smoothing constants."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generating a sample with a particular smoothing constant\n",
    "\n",
    "(e.g. maybe you could make a function called `generate_sample` that gives us a sample corpus generated by the model, using the given smoothing constant, and `compute_corpus_perplexity` to calculate its perplexity, using a possibly different constant.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8369fbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T20:21:20.219754300Z",
     "start_time": "2023-05-21T20:21:20.203308800Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_sample(model: BigramModel, sample_size: int, smoothing_constant: float) -> list:\n",
    "    \"\"\"\n",
    "    Generate a sample of size sample_size from model, using smoothing_constant for LaPlace smoothing\n",
    "    @param model: BigramModel\n",
    "    @param sample_size: int\n",
    "    @param smoothing_constant: float \n",
    "    @return: list of lists of strings\n",
    "    \"\"\"\n",
    "    print(\"\\ngenerating with constant\", smoothing_constant)\n",
    "    list = []\n",
    "    for i in range(sample_size):\n",
    "        list.append(generate_sentence(model, smoothing_constant))\n",
    "    return list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05961914",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T20:21:21.628175500Z",
     "start_time": "2023-05-21T20:21:21.576181700Z"
    }
   },
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "def compute_corpus_perplexity(model: BigramModel, sample: list, smoothing_constant: float) -> float:\n",
    "    \"\"\"\n",
    "    returns the average perplexity of the given sample with the model, using the smoothing constant for add-k smoothing\n",
    "    @param model: BigramModel\n",
    "    @param sample: list\n",
    "    @param smoothing_constant: float\n",
    "    @return: float\n",
    "    \"\"\"\n",
    "    perplexes = []\n",
    "    for sent in sample:\n",
    "        perplexes.append(model.perplexity(sent, smoothing_constant))\n",
    "    return mean(perplexes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547c2d0f",
   "metadata": {},
   "source": [
    "To try this out, we generate a sample of (some number of) sentences using raw probabilities (no smoothing) and test it with LaPlace smoothing (k = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99f00a08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T20:21:37.584971800Z",
     "start_time": "2023-05-21T20:21:23.038692200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generating with constant 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choosing successor for: <s>: 100%|████████████████████████████████| 824/824 [00:13<00:00, 61.73it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Total of weights must be greater than zero",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m n \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m----> 2\u001B[0m raw_sample \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_sample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmy_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[4], line 12\u001B[0m, in \u001B[0;36mgenerate_sample\u001B[1;34m(model, sample_size, smoothing_constant)\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28mlist\u001B[39m \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(sample_size):\n\u001B[1;32m---> 12\u001B[0m     \u001B[38;5;28mlist\u001B[39m\u001B[38;5;241m.\u001B[39mappend(\u001B[43mgenerate_sentence\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msmoothing_constant\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlist\u001B[39m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ICLBigramModel\\generate.py:10\u001B[0m, in \u001B[0;36mgenerate_sentence\u001B[1;34m(model, smoothing_constant)\u001B[0m\n\u001B[0;32m      8\u001B[0m sent \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m<s>\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m sent[\u001B[38;5;28mlen\u001B[39m(sent) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m</s>\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m---> 10\u001B[0m     successor \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchoose_successor\u001B[49m\u001B[43m(\u001B[49m\u001B[43msent\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msent\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msmoothing_constant\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msmoothing_constant\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m     sent\u001B[38;5;241m.\u001B[39mappend(successor)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sent\n",
      "File \u001B[1;32m~\\PycharmProjects\\ICLBigramModel\\model.py:104\u001B[0m, in \u001B[0;36mBigramModel.choose_successor\u001B[1;34m(self, word, smoothing_constant)\u001B[0m\n\u001B[0;32m    102\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m bigram \u001B[38;5;129;01min\u001B[39;00m tqdm(possible_bigrams, ncols\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mChoosing successor for: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mword\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    103\u001B[0m     prob2\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprobability(word, bigram[\u001B[38;5;241m1\u001B[39m], \u001B[38;5;241m0.0\u001B[39m))\n\u001B[1;32m--> 104\u001B[0m successor: \u001B[38;5;28mtuple\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mrandom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchoices\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpossible_bigrams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprob2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    105\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m successor[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\lib\\random.py:535\u001B[0m, in \u001B[0;36mRandom.choices\u001B[1;34m(self, population, weights, cum_weights, k)\u001B[0m\n\u001B[0;32m    533\u001B[0m total \u001B[38;5;241m=\u001B[39m cum_weights[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m0.0\u001B[39m   \u001B[38;5;66;03m# convert to float\u001B[39;00m\n\u001B[0;32m    534\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m total \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m:\n\u001B[1;32m--> 535\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTotal of weights must be greater than zero\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    536\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _isfinite(total):\n\u001B[0;32m    537\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTotal of weights must be finite\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: Total of weights must be greater than zero"
     ]
    }
   ],
   "source": [
    "n = 1\n",
    "raw_sample = generate_sample(my_model, n, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7450c330",
   "metadata": {},
   "source": [
    "We can see some examples below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def token_list2text(sent: list) -> str:\n",
    "    string = ''\n",
    "    for x in sent:\n",
    "        string = string + ' ' + x\n",
    "    return string"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-21T20:17:55.856191700Z",
     "start_time": "2023-05-21T20:17:55.831279400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8e862ff",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-05-21T20:17:57.494709700Z",
     "start_time": "2023-05-21T20:17:57.473131500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 examples:\n",
      "\n",
      " <s> ix </s>\n"
     ]
    }
   ],
   "source": [
    "print(\"1 examples:\\n\")\n",
    "for s in raw_sample[:1]:\n",
    "    print(token_list2text(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cf08fa",
   "metadata": {},
   "source": [
    "To calculate the perplexity of this sample, we can choose a smoothing constant -- let's make it 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "188dc493",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T20:18:00.891349400Z",
     "start_time": "2023-05-21T20:18:00.835761900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341.15541553091344\n"
     ]
    }
   ],
   "source": [
    "laplace_constant = 1.0\n",
    "print(compute_corpus_perplexity(my_model, raw_sample, laplace_constant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "tokens = nltk.word_tokenize(\"letters written respectively in st michael timidly to control your philosophies and prolonged cheering as short well-brushed hair clustered as marriage or destroyed nations who blackmails him considering that floating poetry which assembles in snakes does teething hurt whom indeed exceptionally lively eye roamed again blunderingly this filial devotion said startlingly becoming quite indistinctly indeed well-featured fellow agile like cross-examining a quill pen or motorist among tropic birds whirred and fingering his coat-of-arms nobody eats him lifeless conveniences and brun cleared landscape lay littered floor as\")\n",
    "print(my_model.perplexity(tokens, smoothing_constant=1.0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-21T20:18:08.897846600Z",
     "start_time": "2023-05-21T20:18:07.292563400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "4ffabc2d",
   "metadata": {},
   "source": [
    "To see how the perplexity calculation of this sample varies when we change the smoothing constant we use to calculate it, we can test with 10 fractional constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3934554c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T19:15:49.526774700Z",
     "start_time": "2023-05-21T19:15:02.723804400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test with constant 0.0\n",
      "21.800418088134233\n",
      "\n",
      "Test with constant 0.1\n",
      "inf\n",
      "\n",
      "Test with constant 0.2\n",
      "inf\n",
      "\n",
      "Test with constant 0.3\n",
      "inf\n",
      "\n",
      "Test with constant 0.4\n",
      "inf\n",
      "\n",
      "Test with constant 0.5\n",
      "inf\n",
      "\n",
      "Test with constant 0.6\n",
      "inf\n",
      "\n",
      "Test with constant 0.7\n",
      "inf\n",
      "\n",
      "Test with constant 0.8\n",
      "inf\n",
      "\n",
      "Test with constant 0.9\n",
      "inf\n",
      "\n",
      "Test with constant 1.0\n",
      "inf\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 11):  # should this be 0 or 1?\n",
    "    c = i/10  # 0.0, 0.1, 0.2, ..., 1.0\n",
    "    print(\"\\nTest with constant\", c)\n",
    "    print(compute_corpus_perplexity(my_model, raw_sample, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9ec509",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "The following pattern holds / No pattern is discernible here. Explain how so..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3c8b01",
   "metadata": {},
   "source": [
    "## Varying the smoothing constant used for generation\n",
    "\n",
    "Above we used raw probabilities. Now we will see what happens when we vary the constant used to generate the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb37d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,11):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d383a422",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "The following pattern holds / No pattern is discernible here. Explain how so...\n",
    "\n",
    "Argue whether you should try all smoothing constant combinations (for the generation and for the perplexity calculation)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Discussion\n",
    "\n",
    "Any thoughts about why your results came out the way they did?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "Summary, concerns, questions..."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
